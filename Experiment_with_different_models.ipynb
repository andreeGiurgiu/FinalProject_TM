{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL \n",
    "\n",
    "Jan Korczynski -> jki750/2730097"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BOOKS_PATH = os.path.join('Books_rating.csv')\n",
    "SPORT_PATH = os.path.join('EAsports_FC24_Steam_Reviews.csv')\n",
    "MOVIE_PATH = os.path.join('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPORT CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>review</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>steam_purchase</th>\n",
       "      <th>recieved_for_free</th>\n",
       "      <th>written_during_early_access</th>\n",
       "      <th>author_num_games_owned</th>\n",
       "      <th>author_num_reviews</th>\n",
       "      <th>author_playtime_forever</th>\n",
       "      <th>author_playtime_last_two_weeks</th>\n",
       "      <th>author_playtime_at_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157328534</td>\n",
       "      <td>english</td>\n",
       "      <td>absolute garbage</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>617</td>\n",
       "      <td>30</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157326188</td>\n",
       "      <td>english</td>\n",
       "      <td>9 out of 10 games of pvp will matchmake you ag...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>266</td>\n",
       "      <td>19</td>\n",
       "      <td>2960</td>\n",
       "      <td>2960</td>\n",
       "      <td>2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157325082</td>\n",
       "      <td>english</td>\n",
       "      <td>terrible game\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>8533</td>\n",
       "      <td>2790</td>\n",
       "      <td>8451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157324209</td>\n",
       "      <td>english</td>\n",
       "      <td>h</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1199</td>\n",
       "      <td>1199</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157324180</td>\n",
       "      <td>english</td>\n",
       "      <td>I personally haven't experienced any major bug...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>965</td>\n",
       "      <td>965</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id language                                             review  \\\n",
       "0  157328534  english                                   absolute garbage   \n",
       "1  157326188  english  9 out of 10 games of pvp will matchmake you ag...   \n",
       "2  157325082  english                                    terrible game\\n   \n",
       "3  157324209  english                                                  h   \n",
       "4  157324180  english  I personally haven't experienced any major bug...   \n",
       "\n",
       "   voted_up  votes_up  comment_count  steam_purchase  recieved_for_free  \\\n",
       "0     False         0              0            True              False   \n",
       "1     False         1              0            True              False   \n",
       "2     False         0              0            True              False   \n",
       "3      True         0              0            True              False   \n",
       "4      True         0              0            True              False   \n",
       "\n",
       "   written_during_early_access  author_num_games_owned  author_num_reviews  \\\n",
       "0                        False                       0                   1   \n",
       "1                        False                     266                  19   \n",
       "2                        False                      84                   3   \n",
       "3                        False                       0                   1   \n",
       "4                        False                       0                   1   \n",
       "\n",
       "   author_playtime_forever  author_playtime_last_two_weeks  \\\n",
       "0                      617                              30   \n",
       "1                     2960                            2960   \n",
       "2                     8533                            2790   \n",
       "3                     1199                            1199   \n",
       "4                      965                             965   \n",
       "\n",
       "   author_playtime_at_review  \n",
       "0                        587  \n",
       "1                       2857  \n",
       "2                       8451  \n",
       "3                       1199  \n",
       "4                        965  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sport = pd.read_csv(SPORT_PATH)\n",
    "sport_data = df_sport.drop(['author_last_played', 'created'], axis=1)\n",
    "sport_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values distribution\n",
      "id                                0.000000\n",
      "language                          0.000000\n",
      "review                            0.003881\n",
      "voted_up                          0.000000\n",
      "votes_up                          0.000000\n",
      "comment_count                     0.000000\n",
      "steam_purchase                    0.000000\n",
      "recieved_for_free                 0.000000\n",
      "written_during_early_access       0.000000\n",
      "author_num_games_owned            0.000000\n",
      "author_num_reviews                0.000000\n",
      "author_playtime_forever           0.000000\n",
      "author_playtime_last_two_weeks    0.000000\n",
      "author_playtime_at_review         0.000000\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values distribution\")\n",
    "print(sport_data.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column datatypes: \n",
      "id                                 int64\n",
      "language                          object\n",
      "review                            object\n",
      "voted_up                            bool\n",
      "votes_up                           int64\n",
      "comment_count                      int64\n",
      "steam_purchase                      bool\n",
      "recieved_for_free                   bool\n",
      "written_during_early_access         bool\n",
      "author_num_games_owned             int64\n",
      "author_num_reviews                 int64\n",
      "author_playtime_forever            int64\n",
      "author_playtime_last_two_weeks     int64\n",
      "author_playtime_at_review          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Column datatypes: \")\n",
    "print(sport_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOVIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie = pd.read_csv(MOVIE_PATH)\n",
    "df_movie.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production.   The filming t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production.   The filming t...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(text):\n",
    "    return re.sub(r\"<br\\s*/?>\", \" \", text)\n",
    "\n",
    "\n",
    "df_movie['review'] = df_movie['review'].apply(clean_data)\n",
    "df_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column datatypes: \n",
      "review       object\n",
      "sentiment    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Column datatypes: \")\n",
    "print(df_movie.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOOKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books = pd.read_csv(BOOKS_PATH)\n",
    "df_books.head()\n",
    "initial_length = len(df_books)\n",
    "initial_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values distribution\n",
      "Id                    0.000000\n",
      "Title                 0.000069\n",
      "Price                 0.839610\n",
      "User_id               0.187262\n",
      "profileName           0.187295\n",
      "review/helpfulness    0.000000\n",
      "review/score          0.000000\n",
      "review/time           0.000000\n",
      "review/summary        0.000013\n",
      "review/text           0.000003\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values distribution\")\n",
    "print(df_books.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>AZ0IOBU20TBOP</td>\n",
       "      <td>Rev. Pamela Tinnin</td>\n",
       "      <td>8/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>991440000</td>\n",
       "      <td>Outstanding Resource for Small Church Pastors</td>\n",
       "      <td>I just finished the book, &amp;quot;Wonderful Wors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>A373VVEU6Z9M0N</td>\n",
       "      <td>Dr. Terry W. Dorsett</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1291766400</td>\n",
       "      <td>Small Churches CAN Have Wonderful Worship</td>\n",
       "      <td>Many small churches feel like they can not hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>AGKGOH65VTRR4</td>\n",
       "      <td>Cynthia L. Lajoy \"Cindy La Joy\"</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>Not Just for Pastors!</td>\n",
       "      <td>I just finished reading this amazing book and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0829814000</td>\n",
       "      <td>Wonderful Worship in Smaller Churches</td>\n",
       "      <td>19.40</td>\n",
       "      <td>A3OQWLU31BU1Y</td>\n",
       "      <td>Maxwell Grant</td>\n",
       "      <td>1/1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1222560000</td>\n",
       "      <td>Small church pastor? This is the book on worship</td>\n",
       "      <td>I hadn't been a small church pastor very long ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0595344550</td>\n",
       "      <td>Whispers of the Wicked Saints</td>\n",
       "      <td>10.95</td>\n",
       "      <td>A3Q12RK71N74LB</td>\n",
       "      <td>Book Reader</td>\n",
       "      <td>7/11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1117065600</td>\n",
       "      <td>not good</td>\n",
       "      <td>I bought this book because I read some glowing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                  Title  Price         User_id  \\\n",
       "10  0829814000  Wonderful Worship in Smaller Churches  19.40   AZ0IOBU20TBOP   \n",
       "11  0829814000  Wonderful Worship in Smaller Churches  19.40  A373VVEU6Z9M0N   \n",
       "12  0829814000  Wonderful Worship in Smaller Churches  19.40   AGKGOH65VTRR4   \n",
       "13  0829814000  Wonderful Worship in Smaller Churches  19.40   A3OQWLU31BU1Y   \n",
       "14  0595344550          Whispers of the Wicked Saints  10.95  A3Q12RK71N74LB   \n",
       "\n",
       "                        profileName review/helpfulness  review/score  \\\n",
       "10               Rev. Pamela Tinnin               8/10           5.0   \n",
       "11             Dr. Terry W. Dorsett                1/1           5.0   \n",
       "12  Cynthia L. Lajoy \"Cindy La Joy\"                1/1           5.0   \n",
       "13                    Maxwell Grant                1/1           5.0   \n",
       "14                      Book Reader               7/11           1.0   \n",
       "\n",
       "    review/time                                    review/summary  \\\n",
       "10    991440000     Outstanding Resource for Small Church Pastors   \n",
       "11   1291766400         Small Churches CAN Have Wonderful Worship   \n",
       "12   1248307200                             Not Just for Pastors!   \n",
       "13   1222560000  Small church pastor? This is the book on worship   \n",
       "14   1117065600                                          not good   \n",
       "\n",
       "                                          review/text  \n",
       "10  I just finished the book, &quot;Wonderful Wors...  \n",
       "11  Many small churches feel like they can not hav...  \n",
       "12  I just finished reading this amazing book and ...  \n",
       "13  I hadn't been a small church pastor very long ...  \n",
       "14  I bought this book because I read some glowing...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.dropna(subset=['Price', 'User_id', 'profileName', 'review/summary', 'review/text', 'Title'], inplace=True)\n",
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows deleted 2585452\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows deleted {initial_length - len(df_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values distribution\n",
      "Id                    0.0\n",
      "Title                 0.0\n",
      "Price                 0.0\n",
      "User_id               0.0\n",
      "profileName           0.0\n",
      "review/helpfulness    0.0\n",
      "review/score          0.0\n",
      "review/time           0.0\n",
      "review/summary        0.0\n",
      "review/text           0.0\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values distribution\")\n",
    "print(df_books.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentence id                                               text sentiment  \\\n",
      "0            0                                   absolute garbage   unknown   \n",
      "1            1  9 out of 10 games of pvp will matchmake you ag...   unknown   \n",
      "2            2                                    terrible game\\n   unknown   \n",
      "3            3                                                  h   unknown   \n",
      "4            4  I personally haven't experienced any major bug...   unknown   \n",
      "\n",
      "    topic  \n",
      "0  sports  \n",
      "1  sports  \n",
      "2  sports  \n",
      "3  sports  \n",
      "4  sports  \n"
     ]
    }
   ],
   "source": [
    "# Create a unified dataframe\n",
    "data = []\n",
    "\n",
    "# Add sports reviews\n",
    "for index, row in df_sport.iterrows():\n",
    "    data.append({'text': row['review'], 'sentiment': 'unknown', 'topic': 'sports'})\n",
    "\n",
    "# Add movie reviews\n",
    "for index, row in df_movie.iterrows():\n",
    "    data.append({'text': row['review'], 'sentiment': row['sentiment'], 'topic': 'movie'})\n",
    "\n",
    "# Add book reviews\n",
    "for index, row in df_books.iterrows():\n",
    "    data.append({'text': row['review/text'], 'sentiment': 'unknown', 'topic': 'book'})\n",
    "\n",
    "# Convert to a DataFrame\n",
    "final_df = pd.DataFrame(data)\n",
    "\n",
    "# If you have or need sentence IDs\n",
    "final_df = final_df.reset_index().rename(columns={'index': 'sentence id'})\n",
    "\n",
    "# Show the dataframe\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/andreeagiurgiu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andreeagiurgiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence   topic sentiment\n",
      "0                                   absolute garbage  sports   neutral\n",
      "1  9 out of 10 games of pvp will matchmake you ag...  sports   neutral\n",
      "2                                      terrible game  sports  negative\n",
      "3  I personally haven't experienced any major bug...  sports   neutral\n",
      "4  Base game is pretty fun but it is even better ...  sports  positive\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sent_tokenize\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentence_data = []\n",
    "\n",
    "# Function to analyze sentiment of individual sentences\n",
    "def analyze_sentence_sentiment_and_store(text):\n",
    "    if not isinstance(text, str):\n",
    "        return\n",
    "    \n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Analyze sentiment for each sentence\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 1:\n",
    "            ss = sid.polarity_scores(sentence)\n",
    "            sentiment = 'positive' if ss['compound'] >= 0.05 else 'negative' if ss['compound'] <= -0.05 else 'neutral'\n",
    "            sentence_data.append({'sentence': sentence, 'topic': row['topic'], 'sentiment': sentiment})\n",
    "\n",
    "# Apply sentiment analysis to the sports and books reviews\n",
    "for index, row in final_df.iterrows():\n",
    "    if row['topic'] != 'movie':  # Assuming movie reviews already have sentiment\n",
    "        analyze_sentence_sentiment_and_store(row['text'])\n",
    "\n",
    "# Create a new DataFrame from the sentence-level data\n",
    "sentence_df = pd.DataFrame(sentence_data)\n",
    "\n",
    "# Display the updated DataFrame with sentence-level sentiment\n",
    "print(sentence_df.head())\n",
    "\n",
    "# Save the sentence-level data to a text file\n",
    "sentence_df.to_csv('sentence_level_output.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.38      0.52    115362\n",
      "     neutral       0.88      0.26      0.40    151818\n",
      "    positive       0.63      0.98      0.76    308358\n",
      "\n",
      "    accuracy                           0.67    575538\n",
      "   macro avg       0.78      0.54      0.56    575538\n",
      "weighted avg       0.74      0.67      0.62    575538\n",
      "\n",
      "tfidf\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.42      0.56    116092\n",
      "     neutral       0.87      0.32      0.47    151434\n",
      "    positive       0.65      0.97      0.78    308012\n",
      "\n",
      "    accuracy                           0.69    575538\n",
      "   macro avg       0.78      0.57      0.60    575538\n",
      "weighted avg       0.74      0.69      0.65    575538\n",
      "\n",
      "tfidf\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.43      0.57    116078\n",
      "     neutral       0.87      0.33      0.48    151641\n",
      "    positive       0.65      0.97      0.78    307819\n",
      "\n",
      "    accuracy                           0.69    575538\n",
      "   macro avg       0.78      0.58      0.61    575538\n",
      "weighted avg       0.75      0.69      0.66    575538\n",
      "\n",
      "airline_count\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.64      0.66    115626\n",
      "     neutral       0.86      0.65      0.74    151764\n",
      "    positive       0.79      0.90      0.84    308148\n",
      "\n",
      "    accuracy                           0.78    575538\n",
      "   macro avg       0.78      0.73      0.75    575538\n",
      "weighted avg       0.79      0.78      0.78    575538\n",
      "\n",
      "airline_count\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.65      0.67    115679\n",
      "     neutral       0.85      0.68      0.76    151448\n",
      "    positive       0.80      0.89      0.84    308411\n",
      "\n",
      "    accuracy                           0.79    575538\n",
      "   macro avg       0.78      0.74      0.76    575538\n",
      "weighted avg       0.79      0.79      0.79    575538\n",
      "\n",
      "airline_count\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.66      0.67    115561\n",
      "     neutral       0.85      0.69      0.76    151705\n",
      "    positive       0.80      0.89      0.85    308272\n",
      "\n",
      "    accuracy                           0.79    575538\n",
      "   macro avg       0.78      0.75      0.76    575538\n",
      "weighted avg       0.79      0.79      0.79    575538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import pathlib\n",
    "import sklearn\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_data(min_val, train_setting):\n",
    "    \n",
    "    # Treat all sentences as string\n",
    "    sentence_df['sentence'] = sentence_df['sentence'].astype(str)\n",
    "    \n",
    "    vectorizer = CountVectorizer(min_df = min_val, # If a token appears fewer times than this, across all documents, it will be ignored\n",
    "                             tokenizer=nltk.word_tokenize, # we use the nltk tokenizer\n",
    "                             stop_words=stopwords.words('english')) # stopwords are removed\n",
    "    text_counts = vectorizer.fit_transform(sentence_df['sentence'])\n",
    "\n",
    "    if train_setting == \"tfidf\":\n",
    "        # Convert raw frequency counts into TF-IDF values\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        setting = tfidf_transformer.fit_transform(text_counts)\n",
    "    \n",
    "    else:\n",
    "        setting = text_counts\n",
    "\n",
    "    #use training data to build classifier\n",
    "    docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "        setting, # model\n",
    "        sentence_df['sentiment'], # the category values for each tweet \n",
    "        test_size = 0.20 # we use 80% for training and 20% for development\n",
    "        ) \n",
    "    # Train a Multimoda Naive Bayes classifier\n",
    "    clf = MultinomialNB().fit(docs_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results, find macro recall\n",
    "    y_pred = clf.predict(docs_test)\n",
    "    target_names = [str(label) for label in sorted(set(y_test))]\n",
    "    \n",
    "    #classification report\n",
    "    return classification_report(y_test, y_pred, target_names = target_names)\n",
    "\n",
    "min_df = [2, 5, 10]\n",
    "dif_settings = ['tfidf', 'airline_count']\n",
    "\n",
    "#results of the experiments with the different settings\n",
    "for model in dif_settings:\n",
    "    for df in min_df:\n",
    "        print(model)\n",
    "        print(df)\n",
    "        print(train_data(df, model))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>absolute garbage</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9 out of 10 games of pvp will matchmake you ag...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>terrible game\\n</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I personally haven't experienced any major bug...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480002</th>\n",
       "      <td>480002</td>\n",
       "      <td>\"Very Bad Death\" is a so so story, but the cha...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480003</th>\n",
       "      <td>480003</td>\n",
       "      <td>Very Bad Deaths was a very great book! Spider ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480004</th>\n",
       "      <td>480004</td>\n",
       "      <td>Anything by Spider Robinson is worth reading. ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480005</th>\n",
       "      <td>480005</td>\n",
       "      <td>Great novel! Easy &amp; enjoyable to read straight...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480006</th>\n",
       "      <td>480006</td>\n",
       "      <td>Another book on welfare reform. Dr. Green invo...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480007 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence id                                               text  \\\n",
       "0                 0                                   absolute garbage   \n",
       "1                 1  9 out of 10 games of pvp will matchmake you ag...   \n",
       "2                 2                                    terrible game\\n   \n",
       "3                 3                                                  h   \n",
       "4                 4  I personally haven't experienced any major bug...   \n",
       "...             ...                                                ...   \n",
       "480002       480002  \"Very Bad Death\" is a so so story, but the cha...   \n",
       "480003       480003  Very Bad Deaths was a very great book! Spider ...   \n",
       "480004       480004  Anything by Spider Robinson is worth reading. ...   \n",
       "480005       480005  Great novel! Easy & enjoyable to read straight...   \n",
       "480006       480006  Another book on welfare reform. Dr. Green invo...   \n",
       "\n",
       "       sentiment   topic  \n",
       "0        unknown  sports  \n",
       "1        unknown  sports  \n",
       "2        unknown  sports  \n",
       "3        unknown  sports  \n",
       "4        unknown  sports  \n",
       "...          ...     ...  \n",
       "480002   unknown    book  \n",
       "480003   unknown    book  \n",
       "480004   unknown    book  \n",
       "480005   unknown    book  \n",
       "480006   unknown    book  \n",
       "\n",
       "[480007 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I wouldn't be caught dead watching the NFL if ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris O'Donnell stated that while filming for ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The whole game was a rollercoaster ride, but L...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zendaya slayed in Dune 2, as she does in all h...</td>\n",
       "      <td>positive</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While my favorite player was playing this matc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Sentiment   Topic\n",
       "0  I wouldn't be caught dead watching the NFL if ...  negative  sports\n",
       "1  Chris O'Donnell stated that while filming for ...   neutral   movie\n",
       "2  The whole game was a rollercoaster ride, but L...  positive  sports\n",
       "3  Zendaya slayed in Dune 2, as she does in all h...  positive   movie\n",
       "4  While my favorite player was playing this matc...  negative  sports"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('sentiment-topic-test (1).tsv', delimiter='\\t')\n",
    "\n",
    "\n",
    "test_df = test_df.drop('sentence id', axis=1)\n",
    "\n",
    "test_df = test_df[['text', 'sentiment', 'topic']]\n",
    "test_df.rename(columns={'text': \"Text\", 'sentiment':'Sentiment', 'topic': 'Topic'}, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolute garbage</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9 out of 10 games of pvp will matchmake you ag...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrible game\\n</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I personally haven't experienced any major bug...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480002</th>\n",
       "      <td>\"Very Bad Death\" is a so so story, but the cha...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480003</th>\n",
       "      <td>Very Bad Deaths was a very great book! Spider ...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480004</th>\n",
       "      <td>Anything by Spider Robinson is worth reading. ...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480005</th>\n",
       "      <td>Great novel! Easy &amp; enjoyable to read straight...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480006</th>\n",
       "      <td>Another book on welfare reform. Dr. Green invo...</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480007 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text   topic\n",
       "0                                        absolute garbage  sports\n",
       "1       9 out of 10 games of pvp will matchmake you ag...  sports\n",
       "2                                         terrible game\\n  sports\n",
       "3                                                       h  sports\n",
       "4       I personally haven't experienced any major bug...  sports\n",
       "...                                                   ...     ...\n",
       "480002  \"Very Bad Death\" is a so so story, but the cha...    book\n",
       "480003  Very Bad Deaths was a very great book! Spider ...    book\n",
       "480004  Anything by Spider Robinson is worth reading. ...    book\n",
       "480005  Great novel! Easy & enjoyable to read straight...    book\n",
       "480006  Another book on welfare reform. Dr. Green invo...    book\n",
       "\n",
       "[480007 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df = final_df[['text','topic']]\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gv/kvbk556j5l3dcb84mlpy_n280000gn/T/ipykernel_3036/798913236.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  topic_df['topic'] = topic_df['topic'].map(label_encoding_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absolute garbage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9 out of 10 games of pvp will matchmake you ag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>terrible game\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I personally haven't experienced any major bug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480002</th>\n",
       "      <td>\"Very Bad Death\" is a so so story, but the cha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480003</th>\n",
       "      <td>Very Bad Deaths was a very great book! Spider ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480004</th>\n",
       "      <td>Anything by Spider Robinson is worth reading. ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480005</th>\n",
       "      <td>Great novel! Easy &amp; enjoyable to read straight...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480006</th>\n",
       "      <td>Another book on welfare reform. Dr. Green invo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480007 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  topic\n",
       "0                                        absolute garbage      0\n",
       "1       9 out of 10 games of pvp will matchmake you ag...      0\n",
       "2                                         terrible game\\n      0\n",
       "3                                                       h      0\n",
       "4       I personally haven't experienced any major bug...      0\n",
       "...                                                   ...    ...\n",
       "480002  \"Very Bad Death\" is a so so story, but the cha...      2\n",
       "480003  Very Bad Deaths was a very great book! Spider ...      2\n",
       "480004  Anything by Spider Robinson is worth reading. ...      2\n",
       "480005  Great novel! Easy & enjoyable to read straight...      2\n",
       "480006  Another book on welfare reform. Dr. Green invo...      2\n",
       "\n",
       "[480007 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoding_map = {'book': 2, 'movie': 1, 'sports': 0}\n",
    "\n",
    "# Apply the same mapping to the test dataset\n",
    "topic_df['topic'] = topic_df['topic'].map(label_encoding_map)\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, dev = train_test_split(topic_df, test_size=0.1, random_state=0,\n",
    "                            stratify=topic_df[['topic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 16:03:39.372378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration # https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model\n",
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.overwrite_output_dir=True # overwrite existing saved models in the same directory\n",
    "model_args.evaluate_during_training=True # to perform evaluation while training the model\n",
    "# (eval data should be passed to the training method)\n",
    "\n",
    "model_args.num_train_epochs=10 # number of epochs\n",
    "model_args.train_batch_size=32 # batch size\n",
    "model_args.learning_rate=4e-6 # learning rate\n",
    "model_args.max_seq_length=256 # maximum sequence length\n",
    "# Note! Increasing max_seq_len may provide better performance, but training time will increase.\n",
    "# For educational purposes, we set max_seq_len to 256.\n",
    "\n",
    "# Early stopping to combat overfitting: https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping\n",
    "model_args.use_early_stopping=True\n",
    "model_args.early_stopping_delta=0.01 # \"The improvement over best_eval_loss necessary to count as a better checkpoint\"\n",
    "model_args.early_stopping_metric='eval_loss'\n",
    "model_args.early_stopping_metric_minimize=True\n",
    "model_args.early_stopping_patience=2\n",
    "model_args.evaluate_during_training_steps=32 # how often you want to run validation in terms of training steps (or batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each epoch will have 49 steps.\n"
     ]
    }
   ],
   "source": [
    "model_args.train_batch_size =10000 # You can adjust this number as needed\n",
    "\n",
    "# Recalculate steps per epoch\n",
    "steps_per_epoch = int(np.ceil(len(topic_df) / float(model_args.train_batch_size)))\n",
    "print('Each epoch will have {:,} steps.'.format(steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('roberta', 'roberta-base', num_labels=3, args=model_args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "  0%|                                                   | 0/864 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable To disable this warning, you can either:\n",
      "To disable this warning, you can either:\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable \t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable \t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISMTOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "865it [04:25,  3.26it/s]                                                        \n",
      "Epoch 1 of 10:   0%|                                     | 0/10 [00:00<?, ?it/s]\n",
      "Running Epoch 1 of 10:   0%|                             | 0/44 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "_, history = model.train_model(train, eval_df=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(dev)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = given_test_df[['text', 'topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding_map = {'book': 2, 'movie': 1, 'sports': 0}\n",
    "\n",
    "# Apply the same mapping to the test dataset\n",
    "test_df['topic'] = test_df['topic'].map(label_encoding_map)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted, probabilities = model.predict(test_df['Text'].to_list())\n",
    "test_df['predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['sports', 'movie', 'book']\n",
    "print(classification_report(test_df['Topic'], test_df['predicted'], target_names=categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data\n",
    "classes = ['sports', 'movie', 'book']\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "# Set the color palette\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Plotting\n",
    "x = range(len(classes))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.2\n",
    "plt.bar(x, precision, color='skyblue', width=bar_width, label='Precision')\n",
    "plt.bar([i + bar_width for i in x], recall, color='lightgreen', width=bar_width, label='Recall')\n",
    "plt.bar([i + 2 * bar_width for i in x], f1_score, color='salmon', width=bar_width, label='F1-score')\n",
    "\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Precision, Recall, and F1-score for Different Classes')\n",
    "plt.xticks([i + bar_width for i in x], classes)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "# Add counts on top of bars\n",
    "for i, v in enumerate(precision):\n",
    "    plt.text(i, v + 0.02, str(v), color='black', ha='center')\n",
    "    plt.text(i + bar_width, recall[i] + 0.02, str(recall[i]), color='black', ha='center')\n",
    "    plt.text(i + 2 * bar_width, f1_score[i] + 0.02, str(f1_score[i]), color='black', ha='center')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
